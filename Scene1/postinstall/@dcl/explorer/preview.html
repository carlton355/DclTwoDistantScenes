<!DOCTYPE html>
<html>
  <head>
    <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
    <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
    <title>Decentraland Realtime Preview</title>
    <style>
      html,
      body {
        margin: 0;
        padding: 0;
        height: 100%;
        overflow: hidden;
        touch-action: none;

        background: #74a4d5;
      }

      #gameContainer {
        width: 100vw;
        height: 100vh;
        position: relative;
      }

      #gameContainer.loaded {
        width: 100%;
        height: 100%;
        margin: auto;
      }

      #gameContainer.loaded,
      body {
        background: #000 url(images/decentraland-connect/decentraland-loading.gif) no-repeat 50% 50% !important;
        background-size: 150px 150px !important;
      }
      @media screen and (min-height: 500px) {
        body {
          background: #000 url(images/decentraland-connect/decentraland-loading.gif) no-repeat 50% 50% !important;
          background-size: 150px 150px !important;
        }
      }
      @media screen and (min-height: 800px) {
        #gameContainer.loaded,
        body {
          background: #000 url(images/decentraland-connect/decentraland-loading.gif) no-repeat 50% 50% !important;
          background-size: 150px 150px !important;
        }
      }

      * {
        box-sizing: border-box;
      }

      body {
        color: #fff;
        font-family: 'open sans', roboto, 'helvetica neue', sans-serif;
        font-size: 0.8em;
      }

      canvas {
        position: relative;
        z-index: 1000;
        width: 100%;
        height: 100%;
      }

      .dcl-loading .progress {
        display: block;
      }

      #overlay {
        display: block;
        width: 100%;
        height: 100%;
        top: 0;
        left: 0;
        right: 0;
        bottom: 0;
        z-index: 2;

        background: #74a4d5;
        background-position: center center;

        opacity: 0.15;
      }

      .progress {
        position: absolute;
        height: 30px;
        width: 100%;
        bottom: 0;
        left: 0;
        right: 0;
        border-style: solid;
        border-width: thick;
        border-left: none;
        border-right: none;
        border-top: 3px solid #000;
        border-bottom: 3px solid #000;
        text-align: center;
        border-color: #000;
        background: #000;
        display: none;
      }

      .progress .full {
        float: left;
        width: 0%;
        height: 100%;
        display: inline-flex;
        background: linear-gradient(270deg, #fc9965 4.62%, #ff5273 58.77%, #de3959 100%);
      }

      .progress.loaded {
        z-index: 9;
      }

      .progress.ingame .full {
        animation: none;
      }

      #progress-bar-inner {
        width: 0%;
        transition: width 0.2s;
        animation: none;
      }

      .hidden-error {
        display: none !important;
      }

      body.error {
        background: black !important;
        background-image: none !important;
      }

      body.error #gameContainer {
        display: none !important;
      }

      body.error #progress-bar {
        display: none !important;
        z-index: 10;
      }

      body.error #gameContainer {
        background: black !important;
        background-image: none !important;
      }

      @keyframes progress_30 {
        from {
          width: 0;
        }

        to {
          width: 30%;
        }
      }

      @keyframes progress_50 {
        from {
          width: 30%;
        }

        to {
          width: 50%;
        }
      }

      body.dcl-loading #load-messages-wrapper {
        display: flex;
      }
      #load-messages-wrapper {
        display: none;
        justify-content: center;
        align-items: center;
        flex-direction: column;
        z-index: 8;

        position: fixed;
        top: 80px;

        min-width: 100%;
        padding-left: 0;
        padding-right: 0;

        color: white;
        text-align: center;
        font-size: 1.25em;
        font-family: sfsemibold, 'Helvetica Neue', Arial, sans-serif;
      }

      #load-messages-wrapper div {
        max-width: 820px;
      }

      @media screen and (min-height: 500px) {
        #load-messages-wrapper {
          top: 20%;

          padding-left: 20%;
          padding-right: 20%;
        }
      }
      @media screen and (min-height: 800px) {
        #load-messages-wrapper {
          top: 35%;

          padding-left: 10%;
          padding-right: 10%;
        }
      }

      @media screen and (min-height: 1000px) {
        #load-messages-wrapper {
          top: 38%;

          padding-left: 10%;
          padding-right: 10%;
        }
      }

      #load-images {
        max-width: 306px;
        max-height: 234px;
      }
      .load-images-wrapper {
        height: 234px;
        margin-bottom: 40px;
        display: flex;
        flex-direction: column;
        align-items: center;
        justify-content: center;
      }
      #subtext-messages-container {
        bottom: 40px;
        left: 0;
        position: fixed;

        min-width: 100%;
        padding-left: 20%;
        padding-right: 20%;

        text-align: center;

        font-size: 1em;
        color: #7d8385;
      }

      #subtext-messages-container div {
        margin: auto;
      }

      div#check-wallet-prompt {
        width: 395px;
        text-align: center;
        background: #43474b;
        border-radius: 100px;
        color: white;
        padding: 14px;
        margin-bottom: 10px;
      }

      #eth-connect-advice {
        display: none;
      }
      #eth-sign-advice {
        display: none;
      }
      .login {
        background: #74a4d5;
        background-position: left 50% bottom 33px;

        position: absolute;
        z-index: 9;
        top: 0;
        left: 0;
        width: 100%;
        height: 100%;
      }
      #eth-login {
        display: none;
      }
      .eth-login-popup {
        width: 70%;
        max-width: 650px;
        height: 446px;

        position: absolute;
        left: 50%;
        top: 40px;
        transform: translate(-50%, 0);
        padding: 34px 44px;

        display: flex;
        flex-direction: column;
        align-items: center;
      }
      #eth-login-confirmation-wrapper {
        width: 100%;

        display: flex;
        flex-direction: column;
        align-items: center;
      }
      @font-face {
        font-family: sfregular;
        src: url(images/decentraland-connect/SF-UI-Text-Regular.otf);
      }
      @font-face {
        font-family: sfsemibold;
        src: url(images/decentraland-connect/SF-UI-Text-Semibold.otf);
      }
      .eth-login-description {
        color: white;
        margin-top: 50px;
        margin-bottom: 50px;
        text-align: center;
        font-size: 16px;
        font-family: sfregular, 'Helvetica Neue', Arial, sans-serif;
      }
      .eth-login-welcome {
        color: white;
        font-family: sfregular, 'Helvetica Neue', Arial, sans-serif;
        font-size: 16px;
        margin-bottom: 2px;
      }
      .code {
        font-family: 'Courier New', Courier, monospace;
      }
      .eth-login-logo {
        width: 262px;
      }
      .eth-login-wallet-icon {
        margin-right: 10px;
        width: 24px;
        height: 23px;
        vertical-align: middle;
      }
      .eth-login-tos {
        max-width: 310px;
        margin-bottom: 50px;
        text-align: center;
      }
      .eth-login-tos-label {
        font-size: 13px;
        font-family: sfregular, 'Helvetica Neue', Arial, sans-serif;
        color: white;
      }
      .eth-login-tos-label > a:any-link {
        color: white;
        font-family: sfsemibold, 'Helvetica Neue', Arial, sans-serif;
      }
      .eth-login-tos-agree {
        width: 20px;
        height: 20px;
        vertical-align: middle;
      }

      .nav-bar {
        background-color: rgba(0, 0, 0, 0.1);
        height: 40px;
        display: flex;
        position: fixed;
        top: 0;
        left: 0;
        width: 100%;
        z-index: 3;
      }
      .nav-bar-content {
        position: absolute;
        right: 50px;
        height: 100%;
        display: flex;
        width: fit-content;

        align-items: center;
        vertical-align: middle;
      }
      @media screen and (min-width: 1200px) {
        .nav-bar-content {
          right: 285px;
        }
      }
      .nav-text {
        color: white;
        font-family: sfregular, 'Helvetica Neue', Arial, sans-serif;
      }
      .nav-discord {
        width: fit-content;

        vertical-align: middle;
        margin: 6px 0 8px 10px;

        border: 1px solid rgba(255, 255, 255, 0.6);
        padding: 4px 12.15px;

        box-sizing: border-box;
        border-radius: 6px;
        text-decoration: none;
      }
      .nav-discord-img {
        width: 14px;
        vertical-align: middle;
      }
      .nav-discord-text {
        margin-left: 2px;
        font-size: 9px;
      }
      .nav-need-support {
        width: fit-content;
        font-size: 11px;
      }

      .footer-bar {
        background: #1c191f;
        height: 33px;
        display: flex;
        position: fixed;
        bottom: 0;
        left: 0;
        width: 100%;
        z-index: 3;
      }
      .footer-bar-content {
        position: absolute;
        right: 50px;
        height: 100%;
        display: flex;
        width: fit-content;

        align-items: center;
        vertical-align: middle;
      }
      @media screen and (min-width: 1200px) {
        .footer-bar-content {
          right: 285px;
        }
      }
      .footer-link {
        margin-left: 34px;
      }
      .footer-text {
        margin-left: 45px;
        vertical-align: middle;
        color: #736e7d;
        font-family: sfregular, 'Helvetica Neue', Arial, sans-serif;
      }
      .footer-icon {
        max-height: 18px;
      }
      .loader {
        --thickness: 5px;
        --diameter: 35px;

        border: var(--thickness) solid #f3f3f3;
        border-top: var(--thickness) solid #ff5273;
        border-radius: 50%;
        width: var(--diameter);
        height: var(--diameter);
        animation: spin 1.24s linear infinite;
      }

      @keyframes spin {
        0% {
          transform: rotate(0deg);
        }
        100% {
          transform: rotate(360deg);
        }
      }

      /* Preview only style */

      .error-overlay-bar {
        display: none;

        width: 100%;
        padding: 5px 0;

        position: absolute;
        top: 0%;
        z-index: 1001;

        background-color: #de3959;
      }
      .error-overlay-title {
        text-align: center;

        font-size: 1rem;
        margin-bottom: 4px;
      }
      .error-overlay-description {
        text-align: center;

        font-size: 0.85rem;
      }
      .error-overlay-button {
        position: absolute;
        right: 20px;
        top: 50%;

        transform: translate(-50%, -50%);

        color: white;

        font-size: 1.5rem;
        font-weight: 600;
        cursor: pointer;

        border: 0;
        background-color: transparent;
      }
      .error-overlay-button:active,
      .error-overlay-button:focus,
      .error-overlay-button:focus:active {
        background-image: none;
        outline: 0;
        box-shadow: none;
      }
    </style>
  </head>

  <body class="dcl-loading">
    <div id="overlay"></div>
    <div id="gameContainer"></div>
    <audio autoplay id="voice-chat-audio"></audio>

    <div id="error-overlay" class="error-overlay-bar">
      <div class="error-overlay-title"></div>
      <div class="error-overlay-description"></div>
      <button class="error-overlay-button" onclick="document.getElementById('error-overlay').style.display = 'none';">
        ⨯
      </button>
    </div>

    <script>
      globalThis.preview = true
    </script>

    <script>
      const isElectron = () => {
        // Renderer process
        if (
          typeof window !== 'undefined' &&
          typeof window.process === 'object' &&
          window.process.type === 'renderer'
        ) {
          return true
        }

        // Main process
        if (typeof process !== 'undefined' && typeof process.versions === 'object' && !!(process.versions).electron) {
          return true
        }

        // Detect the user agent when the `nodeIntegration` option is set to true
        if (
          typeof navigator === 'object' &&
          typeof navigator.userAgent === 'string' &&
          navigator.userAgent.indexOf('Electron') >= 0
        ) {
          return true
        }

        return false
      }

      function mockStorage( { toLocalStorageKey = '' }) {
        let storage = {};

        function update(){
          if (toLocalStorageKey !== ''){
            localStorage.setItem(toLocalStorageKey, JSON.stringify(storage))
          }
        }

        if (toLocalStorageKey !== ''){
          storage = JSON.parse(localStorage.getItem(toLocalStorageKey) || '{}');
        }

        return {
          setItem: async function(key, value) {
            storage[key] = value || '';
            update();
          },
          getItem: async function(key) {
            return (key in storage ? storage[key] : null);
          },
          removeItem: async function(key) {
            delete storage[key];
            update();
          },
          keys: async function() {
            return Object.keys(storage);
          }
        };
      }

      function getPlayerSessionKey() {
        const qs = new URLSearchParams(document.location.search)
        if (qs.has('PLAYER')){
          return 'dcl-preview-' + qs.get('PLAYER').toLowerCase().replace(' ', '_');
        }
        return '';
      }

      function handleError(title, message) {
        const titleElement = document.getElementsByClassName('error-overlay-title')[0]
        const descElement = document.getElementsByClassName('error-overlay-description')[0]
        const containerElement = document.getElementById('error-overlay')

        titleElement.textContent = '' + title || 'Error'

        const item = document.createElement('li')
        item.textContent = ' - ' + message || ''
        descElement.appendChild(item)

        containerElement.style.display = 'block'
      }

      async function getExplorerBaseUrl() {
        const qs = new URLSearchParams(document.location.search)

        if (qs.has('explorer')) {
          return qs.get('explorer')
        }

        if (qs.has('explorer-branch')) {
          return `https://renderer-artifacts.decentraland.org/branch/${qs.get('explorer-branch')}`
        }

        if (qs.has('explorer-version')) {
          return `https://cdn.decentraland.org/@dcl/explorer/${qs.get('explorer-version')}`
        }

        // the CLI tool binds @/explorer to a static server serving the contents of
        // the @dcl/explorer package, it has the same behavior as the CDNs listed
        // above
        return new URL('@/explorer', location.toString()).toString()
      }

      async function getRendererBaseUrl() {
        const qs = new URLSearchParams(document.location.search)

        if (qs.has('renderer-branch')) {
          return `https://renderer-artifacts.decentraland.org/branch/${qs.get('renderer-branch')}`
        }

        if (qs.has('renderer-version')) {
          return `https://cdn.decentraland.org/@dcl/explorer/${qs.get('renderer-version')}`
        }
      }

      async function initKernel() {
        const baseUrl = await getExplorerBaseUrl()
        const rendererBaseUrl = await getRendererBaseUrl() || baseUrl
        const kernelScript = (new URL('index.js', `${baseUrl}/`)).toString()

        await injectScript(kernelScript)

        const container = document.getElementById('gameContainer')
        const DecentralandKernel = globalThis.DecentralandKernel

        if (!DecentralandKernel) throw new Error('DecentralandKernel could not be loaded')

        const kernel = await DecentralandKernel.initKernel({
          kernelOptions: {
            baseUrl,
            previewMode: true,
            persistentStorage: mockStorage({
              toLocalStorageKey: getPlayerSessionKey()
            })
          },
          rendererOptions: {
            container,
            baseUrl: rendererBaseUrl
          }
        })

        const qs = new URLSearchParams(document.location.search)
        const enableLogs = qs.has('DEBUG_KERNEL_LOG')

        kernel.on('trackingEvent', ({ eventName, eventData }) => {
          if (enableLogs) {
            console.log(`> event`, eventName, eventData)
          }
        })

        kernel.on('openUrl', ({ url }) => {
          const newWindow = window.open(url, '_blank', 'noopener,noreferrer')
          if (newWindow != null) newWindow.opener = null
        })

        kernel.on('loadRealtimeVideo', ({ url, provider, streamId, videoId }) => {
          console.log("*** in loadRealtimeVideo ***");
		 	    rtcvideo.debug(rtcvideo);
			    rtcvideo.debug(`Loading Realtime video with url: ${url}, provider: ${provider}, streamId: ${streamId}, videoId: ${videoId}. `);

          if (rtcvideo.getProvider(provider) == null)
          {
            rtcvideo.debug(`no provider with the name ${provider} was found.`);
            return;
          }

		  	  rtcvideo.providers[provider].ensureLoaded();
		  	  rtcvideo.providers[provider].createStream(url, streamId, videoId);
		    });

		    kernel.on('unloadRealtimeVideo', ({ videoId }) => {
			    rtcvideo.debug("*** In unloadRealtimeVideo ***");
			    rtcvideo.providers["AntMediaEnterprise"].destroyStream(videoId);
        })

        kernel.on('accountState', (account) => {
          if (enableLogs) {
            console.log('> account state', account)
          }
        })

        kernel.on('signUp', ({ email }) => {
          if (enableLogs) {
            console.log(`> sign up ${email}`)
          }
        })

        kernel.on('logout', (data) => {
          if (enableLogs) {
            console.log(`> logout ${data}`)
          }
        })

        kernel.on('error', (error) => {
          try {
            handleError('Critical error', '' + (error.error.message || error.error))
          } catch {
            handleError('Critical error', '' + error.error)
          }
        })

        kernel.on('rendererVisible', (event) => {
          document.getElementById('overlay').style.display = event.visible ? 'none' : 'block'
        })

        return kernel
      }

      async function initPreview(kernel) {
        const url = new URLSearchParams(location.search)

        if (url.has('ENABLE_WEB3')) {
          if (!globalThis.ethereum) {
            handleError('Ethereum provider missing', 'There is no Ethereum provider to use')
          } else {
            if ('request' in globalThis.ethereum) {
              await ethereum.request({ method: 'eth_requestAccounts' })
            }

            kernel.authenticate(globalThis.ethereum, false)
          }
        } else {
          kernel.authenticate('wss://rpc.decentraland.org/mainnet?project=cli-preview', true)
        }

        if (isElectron()) {
          initDesktop()
        }
      }


      function initDesktop() {
        // When run within VSCode the isElectron check passes, but it fails here because window.electron does not exist there
        if (!window.electron || !window.electron.ipcRenderer) {
          return
        }

        const ipcRenderer = window.electron.ipcRenderer

        ipcRenderer.on('downloadState', (event, payload) => {
          console.log(payload)
          switch (payload.type) {
            case 'ERROR':
              console.error(payload || 'Unknown launcher error')
              break
            case 'NEW_VERSION':
              event.sender.send('download')
              break
            case 'READY':
              ipcRenderer.send('executeProcess')
              break
            case 'PROGRESS':
              break
          }
        })

        ipcRenderer.send('checkVersion')
      }

      async function  injectScript(url) {
        return new Promise( (resolve, reject) => {
          const theScript = document.createElement('script')
          const persistMessage =
          'If this error persists, please try emptying the cache of your browser and reloading this page.'
          theScript.src = url
          theScript.async = true
          theScript.type = 'application/javascript'
          theScript.crossOrigin = 'anonymous'
          theScript.addEventListener('load', resolve)
          theScript.addEventListener('error', (e) =>
            reject(e.error || new Error(`The script ${url} failed to load.\n${persistMessage}`))
          )
          theScript.addEventListener('abort', () =>
            reject(
              new Error(
                `Script loading aborted: ${url}.\nThis may be caused because you manually stopped the loading or because of a network error.\n${persistMessage}`
              )
            )
          )
          document.body.appendChild(theScript)
        })
      }

      initKernel()
        .then(initPreview)
        .catch((err) => {
          handleError('Error loading kernel', '' + err)
        })
    </script>

    <script type="module">

      //
      // AntMediaEnterprise files
      // 

      //
      // PeerStats
      //
      class PeerStats {
        constructor(streamId) {
          this.streamId = streamId;
          this.totalBytesReceivedCount = 0;
          this.totalBytesSent = 0;
          this.videoPacketsLost = 0;
          this.fractionLost = 0;
          this.startTime = 0;
          this.lastFramesEncoded = 0;
          this.totalFramesEncodedCount = 0;
          this.lastBytesReceived = 0;
          this.lastBytesSent = 0;
          this.currentTimestamp = 0;
          this.lastTime = 0;
          this.timerId = 0;
          this.firstByteSentCount = 0;
          this.firstBytesReceivedCount = 0;
          this.audioLevel = -1;
          this.qualityLimitationReason = "";
          //res width and res height are video source resolutions
          this.resWidth = 0;
          this.resHeight = 0;
          this.srcFps = 0;
          //frameWidth and frameHeight are the resolutions of the sent video
          this.frameWidth = 0;
          this.frameHeight = 0;

          this.videoRoundTripTime = 0;
          this.videoJitter = 0;

          this.audioRoundTripTime = 0;
          this.audioJitter = 0;

          this.audioPacketsLost = 0;

          this.framesReceived = 0;
          this.framesDropped = 0;
          this.framesDecoded = 0;

          this.audioJitterAverageDelay = 0;
          this.videoJitterAverageDelay = 0;
        }

        //kbits/sec
        get averageOutgoingBitrate() {
          return Math.floor(8 * (this.totalBytesSentCount - this.firstByteSentCount) / (this.currentTimestamp - this.startTime));
        }

        //frames per second
        get currentFPS() {
          return (((this.totalFramesEncodedCount - this.lastFramesEncoded) / (this.currentTimestamp - this.lastTime)) * 1000).toFixed(1);
        }
        //kbits/sec
        get averageIncomingBitrate() {
          return Math.floor(8 * (this.totalBytesReceivedCount - this.firstBytesReceivedCount) / (this.currentTimestamp - this.startTime));
        }

        //kbits/sec
        get currentOutgoingBitrate() {
          return Math.floor(8 * (this.totalBytesSentCount - this.lastBytesSent) / (this.currentTimestamp - this.lastTime));
        }

        //kbits/sec
        get currentIncomingBitrate() {
          return Math.floor(8 * (this.totalBytesReceivedCount - this.lastBytesReceived) / (this.currentTimestamp - this.lastTime));
        }

        set currentTime(timestamp) {
          this.lastTime = this.currentTimestamp;
          this.currentTimestamp = timestamp;
          if (this.startTime == 0) {
            this.startTime = timestamp - 1; // do not have zero division error
          }
        }

        set totalBytesReceived(bytesReceived) {
          this.lastBytesReceived = this.totalBytesReceivedCount;
          this.totalBytesReceivedCount = bytesReceived;
          if (this.firstBytesReceivedCount == 0) {
            this.firstBytesReceivedCount = bytesReceived;
          }
        }

        set totalBytesSent(bytesSent) {
          this.lastBytesSent = this.totalBytesSentCount;
          this.totalBytesSentCount = bytesSent;
          if (this.firstByteSentCount == 0) {
            this.firstByteSentCount = bytesSent;
          }
        }
        set totalFramesEncoded(framesEncoded) {
          this.lastFramesEncoded = this.totalFramesEncodedCount;
          this.totalFramesEncodedCount = framesEncoded;
          if (this.lastFramesEncoded == 0) {
            this.lastFramesEncoded = framesEncoded;
          }
        }
      }

      //
      // WebSocketAdaptor 
      //
      class WebSocketAdaptor {
        constructor(initialValues) {

          this.debug = true;
          for (var key in initialValues) {
            if (initialValues.hasOwnProperty(key)) {
              this[key] = initialValues[key];
            }
          }

          this.initWebSocketConnection();
        }

        initWebSocketConnection(callbackConnected) {
          this.connecting = true;
          this.connected = false;
          this.pingTimerId = -1;

          this.wsConn = new WebSocket(this.websocket_url);

          this.wsConn.onopen = () => {
            if (this.debug) {
              console.debug("websocket connected");
            }

            this.pingTimerId = setInterval(() => {
              this.sendPing();
            }, 3000);

            this.connected = true;
            this.connecting = false;
            this.callback("initialized");

            if (typeof callbackConnected != "undefined") {
              callbackConnected();
            }
          }

          this.wsConn.onmessage = (event) => {

            var obj = JSON.parse(event.data);

            if (obj.command == "start") {
              //this command is received first, when publishing so playmode is false
              if (this.debug) {
                console.debug("received start command");
              }
              this.webrtcadaptor.startPublishing(obj.streamId);
            } else if (obj.command == "takeCandidate") {
              if (this.debug) {
                console.debug("received ice candidate for stream id " + obj.streamId);
                console.debug(obj.candidate);
              }
              this.webrtcadaptor.takeCandidate(obj.streamId, obj.label, obj.candidate);
            } else if (obj.command == "takeConfiguration") {
              if (this.debug) {
                console.debug("received remote description type for stream id: " + obj.streamId + " type: " + obj.type);
              }
              this.webrtcadaptor.takeConfiguration(obj.streamId, obj.sdp, obj.type, obj.idMapping);
            }
            else if (obj.command == "stop") {
              if (this.debug) {
                console.debug("Stop command received");
              }
              this.webrtcadaptor.closePeerConnection(obj.streamId);
            }
            else if (obj.command == "error") {
              this.callbackError(obj.definition);
            }
            else if (obj.command == "notification") {
              this.callback(obj.definition, obj);
              if (obj.definition == "play_finished" || obj.definition == "publish_finished") {
                this.webrtcadaptor.closePeerConnection(obj.streamId);
              }
            }
            else if (obj.command == "streamInformation") {
              this.callback(obj.command, obj);
            }
            else if (obj.command == "roomInformation") {
              this.callback(obj.command, obj);
            }
            else if (obj.command == "pong") {
              this.callback(obj.command);
            }
            else if (obj.command == "trackList") {
              this.callback(obj.command, obj);
            }
            else if (obj.command == "connectWithNewId") {
              this.multiPeerStreamId = obj.streamId;
              this.join(obj.streamId);
            }
            else if (obj.command == "peerMessageCommand") {
              this.callback(obj.command, obj);
            }
          }

          this.wsConn.onerror = (error) => {
            this.connecting = false;
            this.connected = false;
            console.info(" error occured: " + JSON.stringify(error));
            this.clearPingTimer();
            this.callbackError("WebSocketNotConnected", error)
          }

          this.wsConn.onclose = (event) => {
            this.connecting = false;
            this.connected = false;
            if (this.debug) {
              console.debug("connection closed.");
            }
            this.clearPingTimer();
            this.callback("closed", event);
          }
        }

        clearPingTimer() {
          if (this.pingTimerId != -1) {
            if (this.debug) {
              console.debug("Clearing ping message timer");
            }
            clearInterval(this.pingTimerId);
            this.pingTimerId = -1;
          }
        }

        sendPing() {
          var jsCmd = {
            command: "ping"
          };
          this.wsConn.send(JSON.stringify(jsCmd));
        }

        close() {
          this.wsConn.close();
        }

        send(text) {
          if (this.connecting == false && this.connected == false) {
            //try to reconnect
            this.initWebSocketConnection(() => {
              this.send(text);
            });
            return;
          }
          this.wsConn.send(text);
          if (this.debug) {
            console.debug("sent message:" + text);
          }
        }

        isConnected() {
          return this.connected;
        }

        isConnecting() {
          return this.connecting;
        }
      }

      //
      // SoundMeter
      //
      export function SoundMeter(context) {
        this.context = context;
        this.instant = 0.0;
        this.script = context.createScriptProcessor(2048, 1, 1);
        const that = this;
        this.script.onaudioprocess = function (event) {
          const input = event.inputBuffer.getChannelData(0);
          let i;
          let sum = 0.0;

          for (i = 0; i < input.length; ++i) {
            sum += input[i] * input[i];
          }

          that.instant = Math.sqrt(sum / input.length);
        };
      }

      SoundMeter.prototype.connectToSource = function (stream, callback) {
        try {
          this.mic = this.context.createMediaStreamSource(stream);
          this.mic.connect(this.script);
          // necessary to make sample run, but should not be.
          this.script.connect(this.context.destination);
          if (typeof callback !== 'undefined') {
            callback(null);
          }
        } catch (e) {
          console.error(e);
          if (typeof callback !== 'undefined') {
            callback(e);
          }
        }
      };

      SoundMeter.prototype.stop = function () {
        this.mic.disconnect();
        this.script.disconnect();
      };

      //
      // WebRtcAdaptor
      //
      class ReceivingMessage {
        constructor(size) {
          this.size = size;
          this.received = 0;
          this.data = new ArrayBuffer(size);
        }
      }

      class WebRTCAdaptor {
        constructor(initialValues) {
          this.peerconnection_config = null;
          this.sdp_constraints = null;
          this.remotePeerConnection = new Array();
          this.remotePeerConnectionStats = new Array();
          this.remoteDescriptionSet = new Array();
          this.iceCandidateList = new Array();
          this.roomName = null;
          this.videoTrackSender = null;
          this.audioTrackSender = null;
          this.playStreamId = new Array();
          this.currentVolume = null;
          this.originalAudioTrackGainNode = null;
          this.videoTrack = null;
          this.audioTrack = null;
          this.smallVideoTrack = null;
          this.audioContext = null;
          this.soundOriginGainNode = null;
          this.secondStreamGainNode = null;
          this.localStream = null;
          this.bandwidth = 900; //default bandwidth kbps
          this.isMultiPeer = false; //used for multiple peer client
          this.multiPeerStreamId = null;   //used for multiple peer client
          this.webSocketAdaptor = null;
          this.isPlayMode = false;
          this.debug = false;
          this.viewerInfo = "";
          this.publishStreamId = null;
          this.blackFrameTimer = null;
          this.idMapping = new Array();


          var threshold = 0.08;
          this.soundMeters = new Array();
          this.soundLevelList = new Array();

          /**
           * This is used when only data is brodcasted with the same way video and/or audio.
             * The difference is that no video or audio is sent when this field is true 
           */
          this.onlyDataChannel = false;

          /**
           * For audio check when the user is muted itself.
           * Check enableAudioLevelWhenMuted
           */
          this.mutedAudioStream = null;
          this.meterRefresh = null;

          /**
           * While publishing and playing streams data channel is enabled by default
           */
          this.dataChannelEnabled = true;

          this.receivingMessages = new Map();

          this.publishMode = "camera"; //screen, screen+camera

          /**
           * Supported candidate types. Below types are for both sending and receiving candidates.
           * It means if when client receives candidate from STUN server, it sends to the server if candidate's protocol
           * is in the list. Likely, when client receives remote candidate from server, it adds as ice candidate
           * if candidate protocol is in the list below.
           */
          this.candidateTypes = ["udp", "tcp"];


          this.desktopStream = null;

          /**
           * The cam_location below is effective when camera and screen is send at the same time.
           * possible values are top and bottom. It's on right all the time
           */
          this.camera_location = "top"

          /**
           * The cam_margin below is effective when camera and screen is send at the same time.
           * This is the margin value in px from the edges
           */
          this.camera_margin = 15;

          /**
           * this camera_percent is how large the camera view appear on the screen. It's %15 by default.
           */
          this.camera_percent = 15;

          for (var key in initialValues) {
            if (initialValues.hasOwnProperty(key)) {
              this[key] = initialValues[key];
            }
          }

          this.localVideo = document.getElementById(this.localVideoId);
          this.remoteVideo = document.getElementById(this.remoteVideoId);

          //A dummy stream created to replace the tracks when camera is turned off.
          this.dummyCanvas = document.createElement("canvas");

          // It should be compatible with previous version
          if (this.mediaConstraints.video == "camera") {
            this.publishMode = "camera";
          }
          else if (this.mediaConstraints.video == "screen") {
            this.publishMode = "screen";
          }
          else if (this.mediaConstraints.video == "screen+camera") {
            this.publishMode = "screen+camera";
          }

          //Check browser support for screen share function
          this.checkBrowserScreenShareSupported();

          if (!this.isPlayMode && !this.onlyDataChannel && typeof this.mediaConstraints != "undefined" && this.localStream == null) {
            this.checkWebRTCPermissions();

            // Get devices only in publish mode.
            this.getDevices();
            this.trackDeviceChange();

            if (typeof this.mediaConstraints.video != "undefined" && this.mediaConstraints.video != false) {
              this.openStream(this.mediaConstraints, this.mode);
            }
            else {
              // get only audio
              var media_audio_constraint = { audio: this.mediaConstraints.audio };
              this.navigatorUserMedia(media_audio_constraint, stream => {
                this.gotStream(stream);
              }, true)
            }
          }
          else {
            //just playing, it does not open any stream
            this.checkWebSocketConnection();
          }
        }
        setDesktopwithCameraSource(stream, streamId, audioStream, onEndedCallback) {
          this.desktopStream = stream;
          this.navigatorUserMedia({ video: true, audio: false }, cameraStream => {
            this.smallVideoTrack = cameraStream.getVideoTracks()[0];

            //create a canvas element
            var canvas = document.createElement("canvas");
            var canvasContext = canvas.getContext("2d");

            //create video element for screen
            //var screenVideo = document.getElementById('sourceVideo');
            var screenVideo = document.createElement('video');

            screenVideo.srcObject = stream;
            screenVideo.play();
            //create video element for camera
            var cameraVideo = document.createElement('video');

            cameraVideo.srcObject = cameraStream;
            cameraVideo.play();
            var canvasStream = canvas.captureStream(15);

            if (this.localStream == null) {
              this.gotStream(canvasStream);
            }
            else {
              this.updateVideoTrack(canvasStream, streamId, this.mediaConstraints, onended, null);
            }
            if (onEndedCallback != null) {
              stream.getVideoTracks()[0].onended = function (event) {
                onEndedCallback(event);
              }
            }

            //update the canvas
            setInterval(() => {
              //draw screen to canvas
              canvas.width = screenVideo.videoWidth;
              canvas.height = screenVideo.videoHeight;
              canvasContext.drawImage(screenVideo, 0, 0, canvas.width, canvas.height);

              var cameraWidth = screenVideo.videoWidth * (this.camera_percent / 100);
              var cameraHeight = (cameraVideo.videoHeight / cameraVideo.videoWidth) * cameraWidth

              var positionX = (canvas.width - cameraWidth) - this.camera_margin;
              var positionY;

              if (this.camera_location == "top") {
                positionY = this.camera_margin;
              }
              else { //if not top, make it bottom
                //draw camera on right bottom corner
                positionY = (canvas.height - cameraHeight) - this.camera_margin;
              }
              canvasContext.drawImage(cameraVideo, positionX, positionY, cameraWidth, cameraHeight);
            }, 66);
          }, true)
        }
        trackDeviceChange() {
          navigator.mediaDevices.ondevicechange = () => {
            this.getDevices();
          }
        }
        getDevices() {
          navigator.mediaDevices.enumerateDevices().then(devices => {
            let deviceArray = new Array();
            let checkAudio = false
            let checkVideo = false
            devices.forEach(device => {
              if (device.kind == "audioinput" || device.kind == "videoinput") {
                deviceArray.push(device);
                if (device.kind == "audioinput") {
                  checkAudio = true;
                }
                if (device.kind == "videoinput") {
                  checkVideo = true;
                }
              }
            });
            this.callback("available_devices", deviceArray);
            if (checkAudio == false && this.localStream == null) {
              console.log("Audio input not found")
              console.log("Retrying to get user media without audio")
              if (this.inputDeviceNotFoundLimit < 2) {
                if (checkVideo != false) {
                  this.openStream({ video: true, audio: false }, this.mode)
                  this.inputDeviceNotFoundLimit++;
                } else {
                  console.log("Video input not found")
                  alert("There is no video or audio input")
                }
              }
              else {
                alert("No input device found, publish is not possible");
              }
            }
          }).catch(err => {
            console.error("Cannot get devices -> error name: " + err.name + ": " + err.message);
          });
        }

        prepareStreamTracks(mediaConstraints, audioConstraint, stream, streamId) {
          //this trick, getting audio and video separately, make us add or remove tracks on the fly
          var audioTrack = stream.getAudioTracks()
          if (audioTrack.length > 0 && this.publishMode == "camera") {
            audioTrack[0].stop();
            stream.removeTrack(audioTrack[0]);
          }
          //now get only audio to add this stream
          if (audioConstraint != "undefined" && audioConstraint != false) {
            var media_audio_constraint = { audio: audioConstraint };
            this.navigatorUserMedia(media_audio_constraint, audioStream => {

              audioStream = this.setGainNodeStream(audioStream);
              if (this.originalAudioTrackGainNode !== null) {
                this.originalAudioTrackGainNode.stop();
              }
              this.originalAudioTrackGainNode = audioStream.getAudioTracks()[1];

              //add callback if desktop is sharing
              var onended = event => {
                this.callback("screen_share_stopped");
                this.setVideoCameraSource(streamId, mediaConstraints, null, true);
              }

              if (this.publishMode == "screen") {
                this.updateVideoTrack(stream, streamId, mediaConstraints, onended, true);
                if (audioTrack.length > 0) {
                  var mixedStream = this.mixAudioStreams(stream, audioStream, streamId);
                  this.updateAudioTrack(mixedStream, streamId, null);
                }
                else {
                  this.updateAudioTrack(audioStream, streamId, null);
                }
              }
              else if (this.publishMode == "screen+camera") {
                if (audioTrack.length > 0) {
                  var mixedStream = this.mixAudioStreams(stream, audioStream, streamId);
                  this.updateAudioTrack(mixedStream, streamId, null);
                  this.setDesktopwithCameraSource(stream, streamId, mixedStream, onended);
                }
                else {
                  this.updateAudioTrack(audioStream, streamId, null);
                  this.setDesktopwithCameraSource(stream, streamId, audioStream, onended);
                }
              }
              else {
                if (audioConstraint != false && audioConstraint != undefined) {
                  stream.addTrack(audioStream.getAudioTracks()[0]);
                }
                this.gotStream(stream);
              }
              this.checkWebSocketConnection();
            }, true)
          }
          else {
            if (typeof audioStream != "undefined" && audioStream.getAudioTracks()[0] != null) {
              stream.addTrack(audioStream.getAudioTracks()[0]);
            }
            this.gotStream(stream);
          }
        }

        navigatorUserMedia(mediaConstraints, func, catch_error) {
          if (catch_error == true) {
            navigator.mediaDevices.getUserMedia(mediaConstraints).then(func).catch(error => {
              if (error.name == "NotFoundError") {
                this.getDevices()
              } else {
                this.callbackError(error.name, error.message);
              }
            });
          } else {
            navigator.mediaDevices.getUserMedia(mediaConstraints).then(func)
          }
        }

        /**
         * Get user media
         */
        getUserMedia(mediaConstraints, audioConstraint, streamId) {
          const resetTrack = (stream) => {
            let videoTracks = stream.getVideoTracks();
            let audioTracks = stream.getAudioTracks();

            if (videoTracks.length > 0) {
              if (this.videoTrack !== null)
                this.videoTrack.stop();
              this.videoTrack = videoTracks[0];
            }

            if (audioTracks.length > 0) {
              if (this.audioTrack !== null)
                this.audioTrack.stop();
              this.audioTrack = audioTracks[0];
            }

            if (this.smallVideoTrack)
              this.smallVideoTrack.stop();
            return stream;
          }

          // Check Media Constraint video value screen or screen + camera
          if (this.publishMode == "screen+camera" || this.publishMode == "screen") {
            navigator.mediaDevices.getDisplayMedia(mediaConstraints)
              .then(stream => {
                resetTrack(stream);
                this.prepareStreamTracks(mediaConstraints, audioConstraint, stream, streamId);

              })
              .catch(error => {
                if (error.name === "NotAllowedError") {
                  console.debug("Permission denied error");
                  this.callbackError("ScreenSharePermissionDenied");

                  // Redirect Default Stream Camera
                  if (this.localStream == null) {

                    var mediaConstraints = {
                      video: true,
                      audio: true
                    };

                    this.openStream(mediaConstraints);
                  }
                  else {
                    this.switchVideoCameraCapture(streamId);
                  }

                }
              });
          }
          // If mediaConstraints only user camera
          else {
            this.navigatorUserMedia(mediaConstraints, (stream => {
              resetTrack(stream);
              this.prepareStreamTracks(mediaConstraints, audioConstraint, stream, streamId);
            }), true);
          }
        }

        /**
         * Open media stream, it may be screen, camera or audio
         */
        openStream(mediaConstraints) {
          this.mediaConstraints = mediaConstraints;
          var audioConstraint = false;
          if (typeof mediaConstraints.audio != "undefined" && mediaConstraints.audio != false) {
            audioConstraint = mediaConstraints.audio;
          }

          if (typeof mediaConstraints.video != "undefined") {
            this.getUserMedia(mediaConstraints, audioConstraint);
          }
          else {
            console.error("MediaConstraint video is not defined");
            this.callbackError("media_constraint_video_not_defined");
          }
        }

        /**
         * Closes stream, if you want to stop peer connection, call stop(streamId)
         */
        closeStream() {
          this.localStream.getVideoTracks().forEach(function (track) {
            track.onended = null;
            track.stop();
          });

          this.localStream.getAudioTracks().forEach(function (track) {
            track.onended = null;
            track.stop();
          });
          if (this.videoTrack !== null) {
            this.videoTrack.stop();
          }

          if (this.audioTrack !== null) {
            this.audioTrack.stop();
          }

          if (this.smallVideoTrack !== null) {
            this.smallVideoTrack.stop();
          }
          if (this.originalAudioTrackGainNode) {
            this.originalAudioTrackGainNode.stop();
          }

        }
        /*
        * Checks if we is permitted from browser
        */
        checkWebRTCPermissions() {
          if (!("WebSocket" in window)) {
            console.log("WebSocket not supported.");
            this.callbackError("WebSocketNotSupported");
            return;
          }

          if (typeof navigator.mediaDevices == "undefined" && this.isPlayMode == false) {
            console.log("Cannot open camera and mic because of unsecure context. Please Install SSL(https)");
            this.callbackError("UnsecureContext");
            return;
          }
          if (typeof navigator.mediaDevices == "undefined" || navigator.mediaDevices == undefined || navigator.mediaDevices == null) {
            this.callbackError("getUserMediaIsNotAllowed");
          }
        }

        /**
         * Checks browser supports screen share feature
         * if exist it calls callback with "browser_screen_share_supported"
         */

        checkBrowserScreenShareSupported() {
          if ((typeof navigator.mediaDevices != "undefined" && navigator.mediaDevices.getDisplayMedia) || navigator.getDisplayMedia) {
            this.callback("browser_screen_share_supported");
          }
        };

        enableSecondStreamInMixedAudio(enable) {

          if (this.secondStreamGainNode != null) {
            if (enable) {
              this.secondStreamGainNode.gain.value = 1;
            }
            else {
              this.secondStreamGainNode.gain.value = 0;
            }
          }
        }

        publish(streamId, token, subscriberId, subscriberCode, streamName, mainTrack, metaData) {
          this.publishStreamId = streamId;
          if (this.onlyDataChannel) {
            var jsCmd = {
              command: "publish",
              streamId: streamId,
              token: token,
              subscriberId: typeof subscriberId !== undefined ? subscriberId : "",
              subscriberCode: typeof subscriberCode !== undefined ? subscriberCode : "",
              streamName: typeof streamName !== undefined ? streamName : "",
              mainTrack: typeof mainTrack !== undefined ? mainTrack : "",
              video: false,
              audio: false,
              metaData: metaData,
            };
          }
          //If it started with playOnly mode and wants to publish now
          else if (this.localStream == null) {
            this.navigatorUserMedia(this.mediaConstraints, (stream => {
              this.gotStream(stream);
              var jsCmd = {
                command: "publish",
                streamId: streamId,
                token: token,
                subscriberId: typeof subscriberId !== undefined ? subscriberId : "",
                subscriberCode: typeof subscriberCode !== undefined ? subscriberCode : "",
                streamName: typeof streamName !== undefined ? streamName : "",
                mainTrack: typeof mainTrack !== undefined ? mainTrack : "",
                video: this.localStream.getVideoTracks().length > 0 ? true : false,
                audio: this.localStream.getAudioTracks().length > 0 ? true : false,
                metaData: metaData,
              };
              this.webSocketAdaptor.send(JSON.stringify(jsCmd));
            }), false);
          }
          else {
            var jsCmd = {
              command: "publish",
              streamId: streamId,
              token: token,
              subscriberId: typeof subscriberId !== undefined ? subscriberId : "",
              subscriberCode: typeof subscriberCode !== undefined ? subscriberCode : "",
              streamName: typeof streamName !== undefined ? streamName : "",
              mainTrack: typeof mainTrack !== undefined ? mainTrack : "",
              video: this.localStream.getVideoTracks().length > 0 ? true : false,
              audio: this.localStream.getAudioTracks().length > 0 ? true : false,
              metaData: metaData,
            };
          }
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        joinRoom(roomName, streamId, mode) {
          this.roomName = roomName;

          var jsCmd = {
            command: "joinRoom",
            room: roomName,
            streamId: streamId,
            mode: mode,
          }
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        play(streamId, token, roomId, enableTracks, subscriberId, subscriberCode) {
          this.playStreamId.push(streamId);
          var jsCmd =
          {
            command: "play",
            streamId: streamId,
            token: token,
            room: roomId,
            trackList: enableTracks,
            subscriberId: typeof subscriberId !== undefined ? subscriberId : "",
            subscriberCode: typeof subscriberCode !== undefined ? subscriberCode : "",
            viewerInfo: this.viewerInfo,
          }

          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        stop(streamId) {
          this.closePeerConnection(streamId);

          var jsCmd = {
            command: "stop",
            streamId: streamId,
          };

          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        join(streamId) {
          var jsCmd = {
            command: "join",
            streamId: streamId,
            multiPeer: this.isMultiPeer && this.multiPeerStreamId == null,
            mode: this.isPlayMode ? "play" : "both",
          };

          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        leaveFromRoom(roomName) {
          this.roomName = roomName;
          var jsCmd = {
            command: "leaveFromRoom",
            room: roomName,
          };
          console.log("leave request is sent for " + roomName);

          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        leave(streamId) {
          var jsCmd = {
            command: "leave",
            streamId: this.isMultiPeer && this.multiPeerStreamId != null ? this.multiPeerStreamId : streamId,
          };

          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
          this.closePeerConnection(streamId);
          this.multiPeerStreamId = null;
        }

        getStreamInfo(streamId) {
          var jsCmd = {
            command: "getStreamInfo",
            streamId: streamId,
          };
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        upateStreamMetaData(streamId, metaData) {
          var jsCmd = {
            command: "updateStreamMetaData",
            streamId: streamId,
            metaData: metaData,
          };
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        getRoomInfo(roomName, streamId) {
          var jsCmd = {
            command: "getRoomInfo",
            streamId: streamId,
            room: roomName,
          };
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        enableTrack(mainTrackId, trackId, enabled) {
          var jsCmd = {
            command: "enableTrack",
            streamId: mainTrackId,
            trackId: trackId,
            enabled: enabled,
          };
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        getTracks(streamId, token) {
          this.playStreamId.push(streamId);
          var jsCmd =
          {
            command: "getTrackList",
            streamId: streamId,
            token: token,
          }

          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        gotStream(stream) {
          //NOTE: I couldn't find a possible reason that we call setGainNode here, it creates problems by adding the second audio track therefore commenting it out. Tahir.
          //Also the following line causes multiple audio tracks in a stream. burak
          //stream = this.setGainNodeStream(stream);

          this.localStream = stream;
          if (this.localVideo) {
            this.localVideo.srcObject = stream;
          }
          this.checkWebSocketConnection();
          this.getDevices();
        }

        /**
        * Toggle video track on the server side.
        *
        * streamId is the id of the stream
        * trackId is the id of the track. streamId is also one of the trackId of the stream. If you are having just a single track on your 
        *         stream, you need to give streamId as trackId parameter as well.  
        * enabled is the enable/disable video track. If it's true, server sends video track. If it's false, server does not send video
        
        */
        toggleVideo(streamId, trackId, enabled) {
          var jsCmd = {
            command: "toggleVideo",
            streamId: streamId,
            trackId: trackId,
            enabled: enabled,
          };
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        /**
        * Toggle audio track on the server side.
        *
        * streamId is the id of the stream
        * trackId is the id of the track. streamId is also one of the trackId of the stream. If you are having just a single track on your 
        *         stream, you need to give streamId as trackId parameter as well.  
        * enabled is the enable/disable video track. If it's true, server sends audio track. If it's false, server does not send audio
        *
        */
        toggleAudio(streamId, trackId, enabled) {
          var jsCmd = {
            command: "toggleAudio",
            streamId: streamId,
            trackId: trackId,
            enabled: enabled,
          };
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }


        /**
         * These methods are initialized when the user is muted himself in a publish scenario
         * It will keep track if the user is trying to speak without sending any data to server
         * Please don't forget to disable this function with disableAudioLevelWhenMuted if you use it.
         */
        enableAudioLevelWhenMuted() {
          navigator.mediaDevices.getUserMedia({ video: false, audio: true })
            .then((stream) => {
              this.mutedAudioStream = stream;
              const soundMeter = new SoundMeter(this.audioContext);
              soundMeter.connectToSource(this.mutedAudioStream, (e) => {
                if (e) {
                  alert(e);
                  return;
                }
                this.meterRefresh = setInterval(() => {
                  if (soundMeter.instant.toFixed(2) > 0.1) {
                    this.callback("speaking_but_muted");
                  }
                }, 200);
              });

            })
            .catch(function (err) {
              console.log("Can't get the soundlevel on mute")
            });
        }

        disableAudioLevelWhenMuted() {
          if (this.meterRefresh != null) {
            clearInterval(this.meterRefresh)
          }

          if (this.mutedAudioStream != null) {
            this.mutedAudioStream.getTracks().forEach(function (track) {
              track.stop();
            });
          }
        }

        switchDesktopCapture(streamId) {
          this.publishMode = "screen";

          var audioConstraint = false;
          if (typeof this.mediaConstraints.audio != "undefined" && this.mediaConstraints.audio != false) {
            audioConstraint = this.mediaConstraints.audio;
          }

          if (typeof this.mediaConstraints.video != "undefined" && this.mediaConstraints.video != false) {
            this.mediaConstraints.video = true
          }

          this.getUserMedia(this.mediaConstraints, audioConstraint, streamId);
        }
        /*
        * This method mixed the first stream audio to the second stream audio and 
        * returns mixed stream. 
        * stream: Initiali stream that contain video and audio
        * 
        */
        mixAudioStreams(stream, secondStream, streamId) {
          //console.debug("audio stream track count: " + audioStream.getAudioTracks().length);
          var composedStream = new MediaStream();
          //added the video stream from the screen
          stream.getVideoTracks().forEach(function (videoTrack) {
            composedStream.addTrack(videoTrack);
          });

          this.audioContext = new AudioContext();
          var audioDestionation = this.audioContext.createMediaStreamDestination();

          if (stream.getAudioTracks().length > 0) {
            this.soundOriginGainNode = this.audioContext.createGain();

            //Adjust the gain for screen sound
            this.soundOriginGainNode.gain.value = 1;
            var audioSource = this.audioContext.createMediaStreamSource(stream);

            audioSource.connect(this.soundOriginGainNode).connect(audioDestionation);
          }
          else {
            console.debug("Origin stream does not have audio track")
          }

          if (secondStream.getAudioTracks().length > 0) {
            this.secondStreamGainNode = this.audioContext.createGain();

            //Adjust the gain for second sound
            this.secondStreamGainNode.gain.value = 1;

            var audioSource2 = this.audioContext.createMediaStreamSource(secondStream);
            audioSource2.connect(this.secondStreamGainNode).connect(audioDestionation);
          }
          else {
            console.debug("Second stream does not have audio track")
          }

          audioDestionation.stream.getAudioTracks().forEach(function (track) {
            composedStream.addTrack(track);
            console.log("audio destination add track");
          });

          return composedStream;
        }

        enableAudioLevel(stream, streamId) {

          const soundMeter = new SoundMeter(this.audioContext);

          // Put variables in global scope to make them available to the
          // browser console.
          soundMeter.connectToSource(stream, function (e) {
            if (e) {
              alert(e);
              return;
            }
            console.log("Added sound meter for stream: " + streamId + " = " + soundMeter.instant.toFixed(2));
          });

          this.soundMeters[streamId] = soundMeter;
        }

        getSoundLevelList(streamsList) {
          for (let i = 0; i < streamsList.length; i++) {
            this.soundLevelList[streamsList[i]] = this.soundMeters[streamsList[i]].instant.toFixed(2);
          }
          this.callback("gotSoundList", this.soundLevelList);
        }


        setGainNodeStream(stream) {
          if (this.mediaConstraints.audio != false && typeof this.mediaConstraints.audio != "undefined") {
            // Get the videoTracks from the stream.
            const videoTracks = stream.getVideoTracks();

            // Get the audioTracks from the stream.
            const audioTracks = stream.getAudioTracks();

            /**
            * Create a new audio context and build a stream source,
            * stream destination and a gain node. Pass the stream into 
            * the mediaStreamSource so we can use it in the Web Audio API.
            */
            this.audioContext = new AudioContext();
            let mediaStreamSource = this.audioContext.createMediaStreamSource(stream);
            let mediaStreamDestination = this.audioContext.createMediaStreamDestination();
            this.soundOriginGainNode = this.audioContext.createGain();

            /**
            * Connect the stream to the gainNode so that all audio
            * passes through the gain and can be controlled by it.
            * Then pass the stream from the gain to the mediaStreamDestination
            * which can pass it back to the RTC client.
            */
            mediaStreamSource.connect(this.soundOriginGainNode);
            this.soundOriginGainNode.connect(mediaStreamDestination);

            if (this.currentVolume == null) {
              this.soundOriginGainNode.gain.value = 1;
            }
            else {
              this.soundOriginGainNode.gain.value = this.currentVolume;
            }

            /**
            * The mediaStreamDestination.stream outputs a MediaStream object
            * containing a single AudioMediaStreamTrack. Add the video track
            * to the new stream to rejoin the video with the controlled audio.
            */
            const controlledStream = mediaStreamDestination.stream;

            for (const videoTrack of videoTracks) {
              controlledStream.addTrack(videoTrack);
            }
            for (const audioTrack of audioTracks) {
              controlledStream.addTrack(audioTrack);
            }

            /**
            * Use the stream that went through the gainNode. This
            * is the same stream but with altered input volume levels.
            */
            return controlledStream;
          }
          return stream;
        }

        switchAudioInputSource(streamId, deviceId) {
          //stop the track because in some android devices need to close the current camera stream
          var audioTrack = this.localStream.getAudioTracks()[0];
          if (audioTrack) {
            audioTrack.stop();
          }
          else {
            console.warn("There is no audio track in local stream");
          }

          if (typeof deviceId != "undefined") {
            if (this.mediaConstraints.audio !== true)
              this.mediaConstraints.audio.deviceId = deviceId;
            else
              this.mediaConstraints.audio = { "deviceId": deviceId };
          }
          this.setAudioInputSource(streamId, this.mediaConstraints, null, true, deviceId);
        }


        /**
         * 
         * @param {*} streamId Id of the stream to be changed.
         * @param {*} deviceId Id of the device which will use as a media device
         * @param {*} onEndedCallback callback for when the switching video state is completed, can be used to understand if it is loading or not
         * 
         * This method is used to switch to video capture. 
         */
        switchVideoCameraCapture(streamId, deviceId, onEndedCallback) {
          //stop the track because in some android devices need to close the current camera stream
          var videoTrack = this.localStream.getVideoTracks()[0];
          if (videoTrack) {
            videoTrack.stop();
          }
          else {
            console.warn("There is no video track in local stream");
          }

          this.publishMode = "camera";
          navigator.mediaDevices.enumerateDevices().then(devices => {
            for (let i = 0; i < devices.length; i++) {
              if (devices[i].kind == "videoinput") {
                //Adjust video source only if there is a matching device id with the given one.
                //It creates problems if we don't check that since video can be just true to select default cam and it is like that in many cases.
                if (devices[i].deviceId == deviceId) {
                  if (this.mediaConstraints.video !== true)
                    this.mediaConstraints.video.deviceId = { exact: deviceId };
                  else
                    this.mediaConstraints.video = { deviceId: { exact: deviceId } };
                  this.setVideoCameraSource(streamId, this.mediaConstraints, null, true, deviceId);
                  break;
                }
              }
            };
            //If no matching device found don't adjust the media constraints let it be true instead of a device ID
            console.debug("Given deviceId = " + deviceId + " - Media constraints video property = " + this.mediaConstraints.video);
            this.setVideoCameraSource(streamId, this.mediaConstraints, null, true, deviceId);
          })

        }

        switchDesktopCaptureWithCamera(streamId) {
          if (typeof this.mediaConstraints.video != "undefined" && this.mediaConstraints.video != false) {
            this.mediaConstraints.video = true
          }

          this.publishMode = "screen+camera";

          var audioConstraint = false;
          if (typeof this.mediaConstraints.audio != "undefined" && this.mediaConstraints.audio != false) {
            audioConstraint = this.mediaConstraints.audio;
          }
          this.getUserMedia(this.mediaConstraints, audioConstraint, streamId);
        }

        /**
         * This method updates the local stream. It removes existant audio track from the local stream
         * and add the audio track in `stream` parameter to the local stream
         */
        updateLocalAudioStream(stream, onEndedCallback) {
          var newAudioTrack = stream.getAudioTracks()[0];

          if (this.localStream != null && this.localStream.getAudioTracks()[0] != null) {
            var audioTrack = this.localStream.getAudioTracks()[0];
            this.localStream.removeTrack(audioTrack);
            audioTrack.stop();
            this.localStream.addTrack(newAudioTrack);
          }
          else if (this.localStream != null) {
            this.localStream.addTrack(newAudioTrack);
          }
          else {
            this.localStream = stream;
          }


          if (this.localVideo != null) {   //it can be null
            this.localVideo.srcObject = this.localStream;
          }

          if (onEndedCallback != null) {
            stream.getAudioTracks()[0].onended = function (event) {
              onEndedCallback(event);
            }
          }
        }

        /**
         * This method updates the local stream. It removes existant video track from the local stream
         * and add the video track in `stream` parameter to the local stream
         */
        updateLocalVideoStream(stream, onEndedCallback, stopDesktop) {
          if (stopDesktop && this.desktopStream != null) {
            this.desktopStream.getVideoTracks()[0].stop();
          }

          var newVideoTrack = stream.getVideoTracks()[0];

          if (this.localStream != null && this.localStream.getVideoTracks()[0] != null) {
            var videoTrack = this.localStream.getVideoTracks()[0];
            this.localStream.removeTrack(videoTrack);
            videoTrack.stop();
            this.localStream.addTrack(newVideoTrack);
          }
          else if (this.localStream != null) {
            this.localStream.addTrack(newVideoTrack);
          }
          else {
            this.localStream = stream;
          }

          if (this.localVideo) {
            this.localVideo.srcObject = this.localStream;
          }

          if (onEndedCallback != null) {
            stream.getVideoTracks()[0].onended = function (event) {
              onEndedCallback(event);
            }
          }
        }

        /**
         * This method sets Audio Input Source. 
         * It calls updateAudioTrack function for the update local audio stream.
         */
        setAudioInputSource(streamId, mediaConstraints, onEndedCallback) {
          this.navigatorUserMedia(mediaConstraints, stream => {
            this.updateAudioTrack(stream, streamId, mediaConstraints, onEndedCallback);
          }, true);
        }

        /**
         * This method sets Video Input Source. 
         * It calls updateVideoTrack function for the update local video stream.
         */
        setVideoCameraSource(streamId, mediaConstraints, onEndedCallback, stopDesktop) {
          this.navigatorUserMedia(mediaConstraints, stream => {
            //Why did we update also the audio track here?
            //This audio track update is necessary for such a case:
            //If you enable screen share with browser audio and then 
            //return back to the camera, the audio should be only from mic.
            //If, we don't update audio with the following lines, 
            //the mixed (mic+browser) audio would be streamed in the camera mode.

            stream = this.setGainNodeStream(stream);
            this.updateAudioTrack(stream, streamId, mediaConstraints, onEndedCallback);

            this.updateVideoTrack(stream, streamId, mediaConstraints, onEndedCallback, stopDesktop);
          }, true);
        }

        updateAudioTrack(stream, streamId, onEndedCallback) {
          //These codes cover when audio source change with audio source buttons
          //this.setGainNodeStream should be call before the audio source change
          //this.setGainNodeStream codes calling in prepareStreamTracks function, but it's not calling when audio source change with switchAudioInputSource function
          stream = this.setGainNodeStream(stream);

          if (this.remotePeerConnection[streamId] != null) {
            var audioTrackSender = this.remotePeerConnection[streamId].getSenders().find(function (s) {
              return s.track.kind == "audio";
            });

            if (audioTrackSender) {
              audioTrackSender.replaceTrack(stream.getAudioTracks()[0]).then(result => {
                this.updateLocalAudioStream(stream, onEndedCallback);

              }).catch(function (error) {
                console.log(error.name);
              });
            }
            else {
              console.error("AudioTrackSender is undefined or null");
            }
          }
          else {
            this.updateLocalAudioStream(stream, onEndedCallback);
          }
        }

        updateVideoTrack(stream, streamId, mediaConstraints, onEndedCallback, stopDesktop) {
          if (this.remotePeerConnection[streamId] != null) {
            var videoTrackSender = this.remotePeerConnection[streamId].getSenders().find(function (s) {
              return s.track.kind == "video";
            });

            if (videoTrackSender) {
              videoTrackSender.replaceTrack(stream.getVideoTracks()[0]).then(result => {
                this.updateLocalVideoStream(stream, onEndedCallback, stopDesktop);

              }).catch(error => {
                console.log(error.name);
              });
            }
            else {
              console.error("VideoTrackSender is undefined or null");
            }
          }
          else {
            this.updateLocalVideoStream(stream, onEndedCallback, stopDesktop);
          }
        }

        onTrack(event, streamId) {
          console.log("onTrack");
          if (this.remoteVideo != null) {
            //this.remoteVideo.srcObject = event.streams[0];
            if (this.remoteVideo.srcObject !== event.streams[0]) {
              this.remoteVideo.srcObject = event.streams[0];
              console.log('Received remote stream');
            }
          }
          else {
            var dataObj = {
              stream: event.streams[0],
              track: event.track,
              streamId: streamId,
              trackId: this.idMapping[streamId][event.transceiver.mid],
            }
            this.callback("newStreamAvailable", dataObj);
          }

        }

        iceCandidateReceived(event, streamId) {
          if (event.candidate) {

            var protocolSupported = false;

            if (event.candidate.candidate == "") {
              //event candidate can be received and its value can be "".
              //don't compare the protocols
              protocolSupported = true;
            }
            else if (typeof event.candidate.protocol == "undefined") {
              this.candidateTypes.forEach(element => {
                if (event.candidate.candidate.toLowerCase().includes(element)) {
                  protocolSupported = true;
                }
              });
            }
            else {
              protocolSupported = this.candidateTypes.includes(event.candidate.protocol.toLowerCase());
            }


            if (protocolSupported) {

              var jsCmd = {
                command: "takeCandidate",
                streamId: streamId,
                label: event.candidate.sdpMLineIndex,
                id: event.candidate.sdpMid,
                candidate: event.candidate.candidate
              };

              if (this.debug) {
                console.log("sending ice candiate for stream Id " + streamId);
                console.log(JSON.stringify(event.candidate));
              }
              this.webSocketAdaptor.send(JSON.stringify(jsCmd));
            }
            else {
              console.log("Candidate's protocol(full sdp: " + event.candidate.candidate + ") is not supported. Supported protocols: " + this.candidateTypes);
              if (event.candidate.candidate != "") { //
                this.callbackError("protocol_not_supported", "Support protocols: " + this.candidateTypes.toString() + " candidate: " + event.candidate.candidate);
              }
            }
          }
          else {
            console.log("No event.candidate in the iceCandidate event");
          }
        }


        initDataChannel(streamId, dataChannel) {
          dataChannel.onerror = (error) => {
            console.log("Data Channel Error:", error);
            var obj = {
              streamId: streamId,
              error: error
            };
            console.log("channel status: ", dataChannel.readyState);
            if (dataChannel.readyState != "closed") {
              this.callbackError("data_channel_error", obj);
            }
          };

          dataChannel.onmessage = (event) => {
            var obj = {
              streamId: streamId,
              data: event.data,
            };

            var data = obj.data;

            if (typeof data === 'string' || data instanceof String) {
              this.callback("data_received", obj);
            }
            else {
              var length = data.length || data.size || data.byteLength;

              var view = new Int32Array(data, 0, 1);
              var token = view[0];

              var msg = this.receivingMessages[token];
              if (msg == undefined) {
                var view = new Int32Array(data, 0, 2);
                var size = view[1];
                msg = new ReceivingMessage(size);
                this.receivingMessages[token] = msg;
                if (length > 8) {
                  console.error("something went wrong in msg receiving");
                }
                return;
              }

              var rawData = data.slice(4, length);

              var dataView = new Uint8Array(msg.data);
              dataView.set(new Uint8Array(rawData), msg.received, length - 4);
              msg.received += length - 4;

              if (msg.size == msg.received) {
                obj.data = msg.data;
                this.callback("data_received", obj);
              }
            }
          };

          dataChannel.onopen = () => {
            this.remotePeerConnection[streamId].dataChannel = dataChannel;
            console.log("Data channel is opened");
            this.callback("data_channel_opened", streamId)
          };

          dataChannel.onclose = () => {
            console.log("Data channel is closed");
            this.callback("data_channel_closed", streamId);
          };
        }

        // data channel mode can be "publish" , "play" or "peer" based on this it is decided which way data channel is created
        initPeerConnection(streamId, dataChannelMode) {
          if (this.remotePeerConnection[streamId] == null) {
            var closedStreamId = streamId;
            console.log("stream id in init peer connection: " + streamId + " close stream id: " + closedStreamId);
            this.remotePeerConnection[streamId] = new RTCPeerConnection(this.peerconnection_config);
            this.remoteDescriptionSet[streamId] = false;
            this.iceCandidateList[streamId] = new Array();
            if (!this.playStreamId.includes(streamId)) {
              if (this.localStream != null) {
                //AddStream is deprecated thus updated to the addTrack after version 2.4.2.1
                this.localStream.getTracks().forEach(track => this.remotePeerConnection[streamId].addTrack(track, this.localStream));
              }
            }
            this.remotePeerConnection[streamId].onicecandidate = event => {
              this.iceCandidateReceived(event, closedStreamId);
            }
            this.remotePeerConnection[streamId].ontrack = event => {
              this.onTrack(event, closedStreamId);
            }

            this.remotePeerConnection[streamId].onnegotiationneeded = event => {
              console.log("onnegotiationneeded");
            }

            if (this.dataChannelEnabled) {
              // skip initializing data channel if it is disabled
              if (dataChannelMode == "publish") {
                //open data channel if it's publish mode peer connection 
                const dataChannelOptions = {
                  ordered: true,
                };
                if (this.remotePeerConnection[streamId].createDataChannel) {
                  var dataChannel = this.remotePeerConnection[streamId].createDataChannel(streamId, dataChannelOptions);
                  this.initDataChannel(streamId, dataChannel);
                }
                else {
                  console.warn("CreateDataChannel is not supported");
                }

              } else if (dataChannelMode == "play") {
                //in play mode, server opens the data channel 
                this.remotePeerConnection[streamId].ondatachannel = ev => {
                  this.initDataChannel(streamId, ev.channel);
                };
              }
              else {
                //for peer mode do both for now
                const dataChannelOptions = {
                  ordered: true,
                };

                if (this.remotePeerConnection[streamId].createDataChannel) {
                  var dataChannelPeer = this.remotePeerConnection[streamId].createDataChannel(streamId, dataChannelOptions);
                  this.initDataChannel(streamId, dataChannelPeer);

                  this.remotePeerConnection[streamId].ondatachannel = ev => {
                    this.initDataChannel(streamId, ev.channel);
                  };
                }
                else {
                  console.warn("CreateDataChannel is not supported");
                }
              }
            }

            this.remotePeerConnection[streamId].oniceconnectionstatechange = event => {
              var obj = { state: this.remotePeerConnection[streamId].iceConnectionState, streamId: streamId };
              this.callback("ice_connection_state_changed", obj);

              if (!this.isPlayMode) {
                if (this.remotePeerConnection[streamId].iceConnectionState == "connected") {

                  this.changeBandwidth(this.bandwidth, streamId).then(() => {
                    console.log("Bandwidth is changed to " + this.bandwidth);
                  })
                    .catch(e => console.warn(e));
                }
              }
            }

          }
        }

        closePeerConnection(streamId) {
          if (this.remotePeerConnection[streamId] != null) {
            if (this.remotePeerConnection[streamId].dataChannel != null) {
              this.remotePeerConnection[streamId].dataChannel.close();
            }
            if (this.remotePeerConnection[streamId].signalingState != "closed") {
              this.remotePeerConnection[streamId].close();
              this.remotePeerConnection[streamId] = null;
              delete this.remotePeerConnection[streamId];
              var playStreamIndex = this.playStreamId.indexOf(streamId);
              if (playStreamIndex != -1) {
                this.playStreamId.splice(playStreamIndex, 1);
              }
            }
          }

          if (this.remotePeerConnectionStats[streamId] != null) {
            clearInterval(this.remotePeerConnectionStats[streamId].timerId);
            delete this.remotePeerConnectionStats[streamId];
          }
          if (this.soundMeters[streamId] != null) {
            delete this.soundMeters[streamId];
          }
        }

        signallingState(streamId) {
          if (this.remotePeerConnection[streamId] != null) {
            return this.remotePeerConnection[streamId].signalingState;
          }
          return null;
        }

        iceConnectionState(streamId) {
          if (this.remotePeerConnection[streamId] != null) {
            return this.remotePeerConnection[streamId].iceConnectionState;
          }
          return null;
        }

        gotDescription(configuration, streamId) {
          this.remotePeerConnection[streamId]
            .setLocalDescription(configuration)
            .then(responose => {
              console.debug("Set local description successfully for stream Id " + streamId);

              var jsCmd = {
                command: "takeConfiguration",
                streamId: streamId,
                type: configuration.type,
                sdp: configuration.sdp

              };

              if (this.debug) {
                console.debug("local sdp: ");
                console.debug(configuration.sdp);
              }

              this.webSocketAdaptor.send(JSON.stringify(jsCmd));

            }).catch((error) => {
              console.error("Cannot set local description. Error is: " + error);
            });
        }
        initializeDummyFrame() {
          this.dummyCanvas.getContext('2d').fillRect(0, 0, 320, 240);
          this.replacementStream = this.dummyCanvas.captureStream();
        }

        turnOffLocalCamera(streamId) {
          //Initialize the first dummy frame for switching.
          this.initializeDummyFrame();

          if (this.remotePeerConnection != null) {
            let choosenId;
            if (streamId != null || typeof streamId != "undefined") {
              choosenId = streamId;
            }
            else {
              choosenId = this.publishStreamId;
            }
            this.updateVideoTrack(this.replacementStream, choosenId, this.mediaConstraints, null, true);
          }
          else {
            this.callbackError("NoActiveConnection");
          }

          //We need to send black frames within a time interval, because when the user turn off the camera,
          //player can't connect to the sender since there is no data flowing. Sending a black frame in each 3 seconds resolves it.
          if (this.blackFrameTimer == null) {
            this.blackFrameTimer = setInterval(() => {
              this.initializeDummyFrame();
            }, 3000);
          }
        }

        turnOnLocalCamera(streamId) {
          if (this.blackFrameTimer != null) {
            clearInterval(this.blackFrameTimer);
            this.blackFrameTimer = null;
          }
          if (this.localStream == null) {
            this.navigatorUserMedia(this.mediaConstraints, stream => {
              this.gotStream(stream);
            }, false);
          }
          //This method will get the camera track and replace it with dummy track
          else if (this.remotePeerConnection != null) {
            this.navigatorUserMedia(this.mediaConstraints, stream => {
              let choosenId;
              if (streamId != null || typeof streamId != "undefined") {
                choosenId = streamId;
              }
              else {
                choosenId = this.publishStreamId;
              }
              this.updateVideoTrack(stream, choosenId, this.mediaConstraints, null, true);
            }, false);
          }
          else {
            this.callbackError("NoActiveConnection");
          }
        }

        muteLocalMic() {
          if (this.remotePeerConnection != null) {
            this.localStream.getAudioTracks().forEach(track => track.enabled = false);
          }
          else {
            this.callbackError("NoActiveConnection");
          }
        }

        /**
         * if there is audio it calls callbackError with "AudioAlreadyActive" parameter
         */
        unmuteLocalMic() {
          if (this.remotePeerConnection != null) {
            this.localStream.getAudioTracks().forEach(track => track.enabled = true);
          }
          else {
            this.callbackError("NoActiveConnection");
          }
        }

        takeConfiguration(idOfStream, configuration, typeOfConfiguration, idMapping) {
          var streamId = idOfStream
          var type = typeOfConfiguration;
          var conf = configuration;
          var isTypeOffer = (type == "offer");

          var dataChannelMode = "publish";
          if (isTypeOffer) {
            dataChannelMode = "play";
          }

          this.idMapping[streamId] = idMapping;

          this.initPeerConnection(streamId, dataChannelMode);

          this.remotePeerConnection[streamId].setRemoteDescription(new RTCSessionDescription({
            sdp: conf,
            type: type
          })).then(response => {

            if (this.debug) {
              console.debug("set remote description is succesfull with response: " + response + " for stream : "
                + streamId + " and type: " + type);
              console.debug(conf);
            }

            this.remoteDescriptionSet[streamId] = true;
            var length = this.iceCandidateList[streamId].length;
            console.debug("Ice candidate list size to be added: " + length);
            for (var i = 0; i < length; i++) {
              this.addIceCandidate(streamId, this.iceCandidateList[streamId][i]);
            }
            this.iceCandidateList[streamId] = [];

            if (isTypeOffer) {
              //SDP constraints may be different in play mode
              console.log("try to create answer for stream id: " + streamId);

              this.remotePeerConnection[streamId].createAnswer(this.sdp_constraints)
                .then(configuration => {
                  console.log("created answer for stream id: " + streamId);
                  //support for stereo
                  configuration.sdp = configuration.sdp.replace("useinbandfec=1", "useinbandfec=1; stereo=1");
                  this.gotDescription(configuration, streamId);
                })
                .catch((error) => {
                  console.error("create answer error :" + error);
                });
            }

          }).catch((error) => {
            if (this.debug) {
              console.error("set remote description is failed with error: " + error);
            }
            if (error.toString().indexOf("InvalidAccessError") > -1 || error.toString().indexOf("setRemoteDescription") > -1) {
              /**
               * This error generally occurs in codec incompatibility.
               * AMS for a now supports H.264 codec. This error happens when some browsers try to open it from VP8.
               */
              this.callbackError("notSetRemoteDescription");
            }
          });

        }

        takeCandidate(idOfTheStream, tmpLabel, tmpCandidate) {
          var streamId = idOfTheStream;
          var label = tmpLabel;
          var candidateSdp = tmpCandidate;

          var candidate = new RTCIceCandidate({
            sdpMLineIndex: label,
            candidate: candidateSdp
          });

          var dataChannelMode = "peer";
          this.initPeerConnection(streamId, dataChannelMode);

          if (this.remoteDescriptionSet[streamId] == true) {
            this.addIceCandidate(streamId, candidate);
          }
          else {
            console.debug("Ice candidate is added to list because remote description is not set yet");
            this.iceCandidateList[streamId].push(candidate);
          }
        };

        addIceCandidate(streamId, candidate) {
          var protocolSupported = false;
          if (candidate.candidate == "") {
            //candidate can be received and its value can be "".
            //don't compare the protocols
            protocolSupported = true;
          }
          else if (typeof candidate.protocol == "undefined") {
            this.candidateTypes.forEach(element => {
              if (candidate.candidate.toLowerCase().includes(element)) {
                protocolSupported = true;
              }
            });
          }
          else {
            protocolSupported = this.candidateTypes.includes(candidate.protocol.toLowerCase());
          }

          if (protocolSupported) {

            this.remotePeerConnection[streamId].addIceCandidate(candidate)
              .then(response => {
                if (this.debug) {
                  console.log("Candidate is added for stream " + streamId);
                }
              })
              .catch((error) => {
                console.error("ice candiate cannot be added for stream id: " + streamId + " error is: " + error);
                console.error(candidate);
              });
          }
          else {
            if (this.debug) {
              console.log("Candidate's protocol(" + candidate.protocol + ") is not supported." +
                "Candidate: " + candidate.candidate + " Supported protocols:" + this.candidateTypes);
            }
          }
        };

        startPublishing(idOfStream) {
          var streamId = idOfStream;

          this.initPeerConnection(streamId, "publish");

          this.remotePeerConnection[streamId].createOffer(this.sdp_constraints)
            .then(configuration => {
              this.gotDescription(configuration, streamId);
            })
            .catch((error) => {
              console.error("create offer error for stream id: " + streamId + " error: " + error);
            });
        };

        /**
         * If we have multiple video tracks in coming versions, this method may cause some issues
         */
        getVideoSender(streamId) {
          var videoSender = null;
          if ((adapter.browserDetails.browser === 'chrome' ||
            (adapter.browserDetails.browser === 'firefox' ||
              adapter.browserDetails.browser === 'safari' &&
              adapter.browserDetails.version >= 64)) &&
            'RTCRtpSender' in window &&
            'setParameters' in window.RTCRtpSender.prototype) {
            if (this.remotePeerConnection[streamId] != null) {
              const senders = this.remotePeerConnection[streamId].getSenders();

              for (let i = 0; i < senders.length; i++) {
                if (senders[i].track != null && senders[i].track.kind == "video") {
                  videoSender = senders[i];
                  break;
                }
              }
            }

          }
          return videoSender;
        }

        /**
         * bandwidth is in kbps
         */
        changeBandwidth(bandwidth, streamId) {
          var errorDefinition = "";

          var videoSender = this.getVideoSender(streamId);

          if (videoSender != null) {
            const parameters = videoSender.getParameters();

            if (!parameters.encodings) {
              parameters.encodings = [{}];
            }

            if (bandwidth === 'unlimited') {
              delete parameters.encodings[0].maxBitrate;
            }
            else {
              parameters.encodings[0].maxBitrate = bandwidth * 1000;
            }

            return videoSender.setParameters(parameters)
          }
          else {
            errorDefinition = "Video sender not found to change bandwidth. Streaming may not be active";
          }

          return Promise.reject(errorDefinition);
        };

        getStats(streamId) {
          console.log("peerstatsgetstats = " + this.remotePeerConnectionStats[streamId]);

          this.remotePeerConnection[streamId].getStats(null).then(stats => {
            var bytesReceived = -1;
            var videoPacketsLost = -1;
            var audioPacketsLost = -1;
            var fractionLost = -1;
            var currentTime = -1;
            var bytesSent = -1;
            var audioLevel = -1;
            var qlr = "";
            var framesEncoded = -1;
            var width = -1;
            var height = -1;
            var fps = -1;
            var frameWidth = -1;
            var frameHeight = -1;
            var videoRoundTripTime = -1;
            var videoJitter = -1;

            var audioRoundTripTime = -1;
            var audioJitter = -1;

            var framesDecoded = -1;
            var framesDropped = -1;
            var framesReceived = -1;

            var audioJitterAverageDelay = -1;
            var videoJitterAverageDelay = -1;


            stats.forEach(value => {

              //console.log(value);

              if (value.type == "inbound-rtp" && typeof value.kind != "undefined") {
                bytesReceived += value.bytesReceived;
                if (value.kind == "audio") {
                  audioPacketsLost = value.packetsLost;
                }
                else if (value.kind == "video") {
                  videoPacketsLost = value.packetsLost;
                }

                fractionLost += value.fractionLost;
                currentTime = value.timestamp;


              }
              else if (value.type == "outbound-rtp") {//TODO: SPLIT AUDIO AND VIDEO BITRATES
                bytesSent += value.bytesSent
                currentTime = value.timestamp
                qlr = value.qualityLimitationReason;
                if (value.framesEncoded != null) { //audio tracks are undefined here
                  framesEncoded += value.framesEncoded;
                }
              }
              else if (value.type == "track" && typeof value.kind != "undefined" && value.kind == "audio") {
                if (typeof value.audioLevel != "undefined") {
                  audioLevel = value.audioLevel;
                }

                if (typeof value.jitterBufferDelay != "undefined" && typeof value.jitterBufferEmittedCount != "undefined") {
                  audioJitterAverageDelay = value.jitterBufferDelay / value.jitterBufferEmittedCount;
                }
              }
              else if (value.type == "track" && typeof value.kind != "undefined" && value.kind == "video") {
                if (typeof value.frameWidth != "undefined") {
                  frameWidth = value.frameWidth;
                }
                if (typeof value.frameHeight != "undefined") {
                  frameHeight = value.frameHeight;
                }

                if (typeof value.framesDecoded != "undefined") {
                  framesDecoded = value.framesDecoded;
                }

                if (typeof value.framesDropped != "undefined") {
                  framesDropped = value.framesDropped;
                }

                if (typeof value.framesReceived != "undefined") {
                  framesReceived = value.framesReceived;
                }

                if (typeof value.jitterBufferDelay != "undefined" && typeof value.jitterBufferEmittedCount != "undefined") {
                  videoJitterAverageDelay = value.jitterBufferDelay / value.jitterBufferEmittedCount;
                }
              }
              else if (value.type == "remote-inbound-rtp" && typeof value.kind != "undefined") {

                if (typeof value.packetsLost != "undefined") {
                  if (value.kind == "video") {
                    //this is the packetsLost for publishing
                    videoPacketsLost = value.packetsLost;
                  }
                  else if (value.kind == "audio") {
                    //this is the packetsLost for publishing
                    audioPacketsLost = value.packetsLost;
                  }
                }

                if (typeof value.roundTripTime != "undefined") {
                  if (value.kind == "video") {
                    videoRoundTripTime = value.roundTripTime;
                  }
                  else if (value.kind == "audio") {
                    audioRoundTripTime = value.roundTripTime;
                  }
                }

                if (typeof value.jitter != "undefined") {
                  if (value.kind == "video") {
                    videoJitter = value.jitter;
                  }
                  else if (value.kind == "audio") {
                    audioJitter = value.jitter;
                  }
                }
              }
              else if (value.type == "media-source") {
                if (value.kind == "video") { //returns video source dimensions, not necessarily dimensions being encoded by browser
                  width = value.width;
                  height = value.height;
                  fps = value.framesPerSecond;
                }
              }
            });

            this.remotePeerConnectionStats[streamId].totalBytesReceived = bytesReceived;
            this.remotePeerConnectionStats[streamId].videoPacketsLost = videoPacketsLost;
            this.remotePeerConnectionStats[streamId].audioPacketsLost = audioPacketsLost;
            this.remotePeerConnectionStats[streamId].fractionLost = fractionLost;
            this.remotePeerConnectionStats[streamId].currentTime = currentTime;
            this.remotePeerConnectionStats[streamId].totalBytesSent = bytesSent;
            this.remotePeerConnectionStats[streamId].audioLevel = audioLevel;
            this.remotePeerConnectionStats[streamId].qualityLimitationReason = qlr;
            this.remotePeerConnectionStats[streamId].totalFramesEncoded = framesEncoded;
            this.remotePeerConnectionStats[streamId].resWidth = width;
            this.remotePeerConnectionStats[streamId].resHeight = height;
            this.remotePeerConnectionStats[streamId].srcFps = fps;
            this.remotePeerConnectionStats[streamId].frameWidth = frameWidth;
            this.remotePeerConnectionStats[streamId].frameHeight = frameHeight;
            this.remotePeerConnectionStats[streamId].videoRoundTripTime = videoRoundTripTime;
            this.remotePeerConnectionStats[streamId].videoJitter = videoJitter;
            this.remotePeerConnectionStats[streamId].audioRoundTripTime = audioRoundTripTime;
            this.remotePeerConnectionStats[streamId].audioJitter = audioJitter;
            this.remotePeerConnectionStats[streamId].framesDecoded = framesDecoded;
            this.remotePeerConnectionStats[streamId].framesDropped = framesDropped;
            this.remotePeerConnectionStats[streamId].framesReceived = framesReceived;

            this.remotePeerConnectionStats[streamId].videoJitterAverageDelay = videoJitterAverageDelay;
            this.remotePeerConnectionStats[streamId].audioJitterAverageDelay = audioJitterAverageDelay;


            this.callback("updated_stats", this.remotePeerConnectionStats[streamId]);

          });
        }
        disableStats(streamId) {
          if (this.remotePeerConnectionStats[streamId] != null || typeof this.remotePeerConnectionStats[streamId] != 'undefined') {
            clearInterval(this.remotePeerConnectionStats[streamId].timerId);
          }
        }

        enableStats(streamId) {
          if (this.remotePeerConnectionStats[streamId] == null) {
            this.remotePeerConnectionStats[streamId] = new PeerStats(streamId);
            this.remotePeerConnectionStats[streamId].timerId = setInterval(() => {
              this.getStats(streamId);

            }, 5000);
          }
        }

        /**
         * After calling this function, create new WebRTCAdaptor instance, don't use the the same objectone
         * Because all streams are closed on server side as well when websocket connection is closed.
         */
        closeWebSocket() {
          for (var key in this.remotePeerConnection) {
            this.remotePeerConnection[key].close();
          }
          //free the remote peer connection by initializing again
          this.remotePeerConnection = new Array();
          this.webSocketAdaptor.close();
        }

        checkWebSocketConnection() {
          if (this.webSocketAdaptor == null || (this.webSocketAdaptor.isConnected() == false && this.webSocketAdaptor.isConnecting() == false)) {
            this.webSocketAdaptor = new WebSocketAdaptor({ websocket_url: this.websocket_url, webrtcadaptor: this, callback: this.callback, callbackError: this.callbackError, debug: this.debug });
          }
        }

        peerMessage(streamId, definition, data) {
          var jsCmd = {
            command: "peerMessageCommand",
            streamId: streamId,
            definition: definition,
            data: data,
          };

          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        forceStreamQuality(streamId, resolution) {
          var jsCmd = {
            command: "forceStreamQuality",
            streamId: streamId,
            streamHeight: resolution
          };
          this.webSocketAdaptor.send(JSON.stringify(jsCmd));
        }

        sendData(streamId, data) {
          var CHUNK_SIZE = 16000;
          var dataChannel = this.remotePeerConnection[streamId].dataChannel;
          var length = data.length || data.size || data.byteLength;
          var sent = 0;

          if (typeof data === 'string' || data instanceof String) {
            dataChannel.send(data);
          }
          else {
            var token = Math.floor(Math.random() * 999999);
            let header = new Int32Array(2);
            header[0] = token;
            header[1] = length;

            dataChannel.send(header);

            var sent = 0;
            while (sent < length) {
              var size = Math.min(length - sent, CHUNK_SIZE);
              var buffer = new Uint8Array(size + 4);
              var tokenArray = new Int32Array(1);
              tokenArray[0] = token;
              buffer.set(new Uint8Array(tokenArray.buffer, 0, 4), 0);

              var chunk = data.slice(sent, sent + size);
              buffer.set(new Uint8Array(chunk), 4);
              sent += size;

              dataChannel.send(buffer);
            }
          }
        }
      }

      window.rtcvideo = {};
      rtcvideo.debugOn = true; // turn on to receive RTDebug messages in the console
      rtcvideo.debug = (obj) => { if (rtcvideo.debugOn) console.debug("RTDebug: ", obj) };
      rtcvideo.webRTCAdaptor = null;

      function loadWebRtcPlayer(url, streamId, noStreamCallback) {
        if (rtcvideo.webRTCAdaptor == null) {
          var iceConnected = false;

          rtcvideo.webRTCAdaptor = new WebRTCAdaptor({
            websocket_url: getWebsocketUrl(url),
            mediaConstraints: {
              video: false,
              audio: false
            },
            peerconnection_config: {
              'iceServers': [{ 'urls': 'stun:stun1.l.google.com:19302' }]
            },
            sdp_constraints: {
              OfferToReceiveAudio: true,
              OfferToReceiveVideo: true
            },
            isPlayMode: true,
            debug: rtcvideo.debugOn,
            callback: function (info, description) {

              if (info != "pong") {
                rtcvideo.debug(info);
                rtcvideo.debug(description);
              }

              if (info == "initialized") {
                rtcvideo.debug("initialized");
              }
              else if (info == "streamInformation") {
                rtcvideo.debug("stream information");
                rtcvideo.webRTCAdaptor.play(description.streamId);
              }
              else if (info == "newStreamAvailable") {
                rtcvideo.debug("newStreamAvailable");
                const elementId = rtcvideo.streamToVideoId[description.streamId];
                const el = document.getElementById(elementId);
                el.srcObject = description.stream;
              }
              else if (info == "play_started") {
                rtcvideo.debug("play started");

                const elementId = rtcvideo.streamToVideoId[description.streamId];
                const el = document.getElementById(elementId);

                el.play().then(function (value) {
                  rtcvideo.debug("Play was actioned on the video tag.");
                });

              } else if (info == "play_finished") {
                rtcvideo.debug("play finished");
                //if play_finished event is received, it has two meanings
                //1. stream is really finished 
                //2. ice connection cannot be established and server reports play_finished event
                // check that publish may start again
                if (iceConnected) {
                  //webrtc connection was successful and try to play again with webrtc
                  setTimeout(function () {
                    rtcvideo.webRTCAdaptor.getStreamInfo(description.streamId);
                  }, 3000);
                }
                else {
                  //webrtc connection was not succesfull, switch the next play type(playOrder) if available 
                  if (typeof noStreamCallback != "undefined") {
                    noStreamCallback(obj.streamId);
                  }
                }
              }
              else if (info == "closed") {
                if (typeof description != "undefined") {
                  rtcvideo.debug("Connecton closed: " + JSON.stringify(description));
                }
              }
              else if (info == "bitrateMeasurement") {
                console.debug(description);
              }
              else if (info == "ice_connection_state_changed") {
                console.debug("ice connection state changed to " + description.state);
                if (description.state == "connected" || description.state == "completed") {
                  //it means the ice connection has been established
                  iceConnected = true;
                }
              }
            },
            callbackError: function (error) {
              //some of the possible errors, NotFoundError, SecurityError, PermissionDeniedError
              rtcvideo.debug("error callback: " + JSON.stringify(error));
              if (error == "no_stream_exist") {
                if (typeof noStreamCallback != "undefined") {
                  noStreamCallback(streamId);
                }
              }
            }
          });
        }
      }

      function webrtcNoStreamCallback(streamId) {
        rtcvideo.debug("webrtcNoStrreamCallback for streamId: " + streamId);

        setTimeout(function () {

          rtcvideo.debug(rtcvideo);

          if (rtcvideo.webRTCAdaptor == null) {
            loadWebRtcPlayer(url, streamId, webrtcNoStreamCallback);
          }
          else {
            rtcvideo.webRTCAdaptor.getStreamInfo(streamId);
          }

        }, 3000);
      }

      function getWebsocketUrl(url) {
        // convert http url to websocket url
        // eg "https://stream.dragonpointslive.net:5443/WebRTCAppEE/"
        // to "wss://stream.dragonpointslive.net:5443/WebRTCAppEE/websocket"
        if (url.startsWith("ws")) return url;
        const wssurl = url.replace("http", "ws");
        const full = (wssurl.endsWith('/')) ? wssurl + "websocket" : wssurl + "/websocket";
        rtcvideo.debug(`${url} was converted to ${full} as websocket address`);
        return full;
      }

      function getProvider(providerName) {
        if (providerName == "AntMediaEnterprise") return new AntMediaEnterpriseProvider();
      }

      // Provider model
      class AntMediaEnterpriseProvider {
        // returns the name of the provider
        get name() {
          return "AntMediaEnterprise";
        }

        // load any assets such as loading scripts into the dom. 
        ensureLoaded() {
          // currently all the assets are loaded in the code above
          // this could change after consulation with DCL developers
        }

        // unload assets
        ensureUnloaded() {
          // nothing to do for this provider (see ensureLoaded)
        }

        // initialize and create the stream
        createStream(url, streamId, videoId) {

          loadWebRtcPlayer(url, streamId, webrtcNoStreamCallback);

          const e = (event) => {
            this.playStream(streamId, videoId);
            rtcvideo.webRTCAdaptor.webSocketAdaptor.wsConn.removeEventListener('open', e);
          };

          if (rtcvideo.webRTCAdaptor == null || rtcvideo.webRTCAdaptor.webSocketAdaptor.connected == false)
            rtcvideo.webRTCAdaptor.webSocketAdaptor.wsConn.addEventListener('open', e);
          else
            playStream(streamId, videoId);
        }

        playStream(streamId, videoId) {
          rtcvideo.streams[videoId] = streamId;
          rtcvideo.streamToVideoId[streamId] = videoId;
          rtcvideo.webRTCAdaptor.play(streamId);
        }

        // destroy the stream when component is destroyed.
        destroyStream(videoId) {

          if (rtcvideo.debug) {
            rtcvideo.debug(`rtcvideo.debug: start destroy stream with videoId ${videoId}.`);
            rtcvideo.debug(rtcvideo);
          }

          const streamId = rtcvideo.streams[videoId];
          rtcvideo.webRTCAdaptor.stop(streamId);
          delete rtcvideo.streams[videoId];
          delete rtcvideo.streamToVideoId[streamId];

          if (rtcvideo.webRTCAdaptor.playStreamId.length == 0) {
            rtcvideo.debug(`rtcvideo.debug: closing web socket for ${videoId}.`);
            rtcvideo.webRTCAdaptor.closeWebSocket();
            rtcvideo.debug("Destroying WebRTCAdaptor");
            rtcvideo.webRTCAdaptor = null;
          }

          rtcvideo.debug(`after destroy stream with videoId ${videoId}.`);
          rtcvideo.debug(rtcvideo);

          // remove the video element
          const el = document.getElementById(videoId);
          el.remove();
          rtcvideo.debug(`Video Element ${videoId} was removed from the DOM.`);
        }
      }

      rtcvideo.getProvider = getProvider;
      rtcvideo.providers = { "AntMediaEnterprise": getProvider("AntMediaEnterprise") };
      rtcvideo.streams = {};
      rtcvideo.streamToVideoId = {};

      rtcvideo.debug("All rtc scripts loaded");
      rtcvideo.debug(JSON.parse(JSON.stringify(rtcvideo)));
      rtcvideo.debug(rtcvideo);

    </script>


  </body>
</html>
